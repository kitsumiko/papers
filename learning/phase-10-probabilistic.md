# Phase 10: Probabilistic & Bayesian Approaches

[← Back to Learning Path](../learning-path.md) | [← Previous: Advanced Topics](phase-09-advanced.md)

**Phase Overview**: Beyond language models lies a rich world of probabilistic generative models. This phase covers diffusion models—the technology behind Stable Diffusion and DALL-E—which generate high-quality images by gradually denoising random noise. You'll understand the theoretical foundations connecting diffusion to score matching and stochastic differential equations, and how these models have revolutionized image generation, video synthesis, and even molecular design. While briefer than other phases, these concepts are essential for understanding modern generative AI beyond just text.

## 10.1 Probabilistic Programming
**Goal**: Build probabilistic models programmatically

1. [A Probabilistic Programming Approach to Probabilistic Data Analysis](https://papers.nips.cc/paper/6060-a-probabilistic-programming-approach-to-probabilistic-data-analysis.pdf) (2016)
   - *Why*: Foundation of probabilistic programming

2. [Picture: An Imperative Probabilistic Programming Language for Scene Perception](https://mrkulk.github.io/www_cvpr15/1999.pdf) (2015)
   - *Why*: Vision with probabilistic programming

3. [MCMC using Hamiltonian dynamics](https://arxiv.org/abs/1206.1901) (2012)
   - *Why*: Core inference algorithm (HMC)

## 10.2 Bayesian Deep Learning
**Goal**: Combine deep learning with Bayesian inference

1. [A Bayesian Framework for Modeling Intuitive Dynamics](https://cocosci.berkeley.edu/tom/papers/collisions.pdf) (2009)
   - *Why*: Bayesian models of physical reasoning

---

**Next**: [Phase 11: Computer Vision (Optional) →](phase-11-vision.md)
