# Phase 12: Hardware & Systems

[← Back to Learning Path](../learning-path.md) | [← Previous: Phase 11](phase-11-vision.md)

**Phase Overview**: AI doesn't run on theory alone—hardware and systems design fundamentally shape what's possible. This phase examines how memory bandwidth bottlenecks limit model performance, how specialized hardware accelerators exploit AI workload characteristics, and how distributed training systems coordinate thousands of GPUs to train massive models. Understanding the hardware-software co-design is crucial for making informed decisions about model architecture, for optimizing deployment costs, and for anticipating future directions as specialized AI chips become more prevalent.

## 12.1 Hardware Considerations
**Goal**: Optimize models for specific hardware

1. [High-dimensional on-chip dataflow sensing and routing using spatial photonic networks](https://www.nature.com/articles/s41566-023-01272-3.pdf) (2023)
   - *Why*: Photonic computing for neural networks

2. [A Log-Domain Implementation of the Diffusion Network in Very Large Scale Integration](https://proceedings.neurips.cc/paper_files/paper/2010/file/7bcdf75ad237b8e02e301f4091fb6bc8-Paper.pdf) (2010)
   - *Why*: VLSI implementations of neural networks

---

**Next**: [Phase 13: Policy & Governance →](phase-13-policy.md)
