# papers
A small list of interesting papers.

# 2024.04
- [TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding](https://arxiv.org/pdf/2404.11912v1.pdf)
- [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/pdf/2404.07143v1.pdf)
- [Efficient streaming language models with attention sinks](https://arxiv.org/pdf/2309.17453.pdf)
- [Consciousness in Artificial Intelligence: Insights from the Science of Consciousness](https://arxiv.org/pdf/2308.08708v3.pdf)
- [OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework](https://arxiv.org/pdf/2404.14619)

# 2023
- [Bytes Are All You Need: Transformers Operating Directly On File Bytes](https://arxiv.org/pdf/2306.00238)
- [TabPFN: A transformer that solves small tabular classification problems in a second](https://arxiv.org/pdf/2207.01848v3.pdf)