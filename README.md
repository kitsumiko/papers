# AI/ML Research Papers Collection

> A curated, pedagogically-organized collection of essential research papers spanning the landscape of modern artificial intelligence and machine learning.

[![Papers](https://img.shields.io/badge/papers-132+-blue.svg)](by-date.md)
[![Learning Path](https://img.shields.io/badge/learning-13_phases-green.svg)](learning-path.md)
[![Glossary](https://img.shields.io/badge/glossary-250+_terms-purple.svg)](learning/glossary.md)
[![Last Updated](https://img.shields.io/badge/updated-November_14,_2025-orange.svg)](by-date.md)

---

## üéØ What's Inside

This repository contains **132+ carefully selected research papers** organized in three complementary ways:

1. **üìö [Structured Learning Path](learning-path.md)** - A 13-phase curriculum designed to take you from foundations to cutting-edge research
2. **üìÖ [Chronological Timeline](by-date.md)** - Papers organized by publication date (1997-2025)
3. **üìñ [Comprehensive Glossary](learning/glossary.md)** - 250+ terms, concepts, and acronyms explained with context

**Plus**: [Recommended reading strategies](#-how-to-use-this-repository), [notes on learning](#paper-reading-tips), and [quick start guides](#-quick-start) tailored to your role (beginner, practitioner, researcher, engineer, security specialist).

### Why This Collection?

- **Curated for Learning**: Papers selected for their pedagogical value and impact
- **Pedagogically Organized**: Follow a structured path from basics to advanced topics
- **Modern & Comprehensive**: Covers transformers, LLMs, agents, vision, security, and more
- **Glossary Integrated**: Key terms linked throughout‚Äînever get lost in jargon
- **Open Access Focused**: Most papers freely available; paywalled papers marked üîí
- **Actively Maintained**: Updated with latest research from 2025

---

## üöÄ Quick Start

### For Beginners
Start with the **[Learning Path](learning-path.md)** and follow **Phase 1: Foundations**. Read papers in sequence, focusing on the "Why" explanations. Check the **[Glossary](learning/glossary.md)** whenever you encounter unfamiliar terms.

### For Practitioners
Jump to relevant phases:
- **LLMs & Training**: [Phase 2](learning/phase-02-llms.md)
- **Efficient Models**: [Phase 3](learning/phase-03-attention.md)
- **Production AI**: [Phase 4](learning/phase-04-retrieval.md) (RAG), [Phase 8](learning/phase-08-security.md) (Security)

### For Researchers
Browse the **[Chronological View](by-date.md)** to see latest 2025 research, or deep-dive into:
- [Phase 6: Alternative Architectures](learning/phase-06-architectures.md)
- [Phase 7: Interpretability](learning/phase-07-interpretability.md)
- [Phase 9: Advanced Topics](learning/phase-09-advanced.md)

### Quick Reference
**Need a definition?** ‚Üí Check the **[üìñ Glossary](learning/glossary.md)** for 250+ terms organized by category (architectures, training, NLP, security, etc.)

---

## üéì How to Use This Repository

### Reading Strategies

**üå± The Beginner Path** (3-6 months)
1. Start with [Phase 1: Foundations](learning/phase-01-foundations.md)
2. Read key papers: [Attention Is All You Need](https://arxiv.org/abs/1706.03762) ‚Üí [BERT](https://arxiv.org/abs/1810.04805) ‚Üí [GPT-3](https://arxiv.org/abs/2005.14165)
3. Focus on "Why" explanations before diving deep
4. Take notes on connections between papers

**‚ö° The Practitioner Sprint** (1-2 months)
1. Read Phase 1 summaries for context
2. Deep-dive: [Phase 2](learning/phase-02-llms.md) + [Phase 3](learning/phase-03-attention.md) + [Phase 4](learning/phase-04-retrieval.md)
3. Skim related work sections to understand landscape
4. Implement key techniques from papers

**üî¨ The Researcher Deep-Dive** (Ongoing)
1. Use [chronological view](by-date.md) for latest research
2. Focus on specific phases relevant to your research
3. Read citations and follow paper connections
4. Compare approaches across different papers

**üõ†Ô∏è The Engineer Focus** (2-4 weeks)
1. Priority: [Phase 3](learning/phase-03-attention.md) (Efficiency), [Phase 8](learning/phase-08-security.md) (Security), [Phase 12](learning/phase-12-hardware.md) (Hardware)
2. Focus on implementation details and benchmarks
3. Note production considerations and trade-offs

**ÔøΩ The Security Specialist** (1-2 weeks)
1. Core: [Phase 8](learning/phase-08-security.md)
2. Context: [Phase 2](learning/phase-02-llms.md) (LLM basics), [Phase 5](learning/phase-05-reasoning.md) (Alignment)
3. Focus on threat models and defense mechanisms

### Paper Reading Tips

1. **Start with abstracts** - Understand the core contribution
2. **Read "Why" annotations** - Context before content
3. **Check the [üìñ Glossary](learning/glossary.md)** - Look up unfamiliar terms
4. **Follow the narrative** - Papers build on each other
5. **Take notes** - Document connections and insights
6. **Implement key ideas** - Hands-on learning reinforces concepts

---

## üìñ Learning Path Overview

The learning path is organized into **13 progressive phases**, each building on previous knowledge:

| Phase | Topic | Papers | Focus |
|-------|-------|--------|-------|
| **[1](learning/phase-01-foundations.md)** | üèóÔ∏è **Foundations** | 15 | Deep learning basics, embeddings, CNNs, RNNs, GANs, tokenization |
| **[2](learning/phase-02-llms.md)** | ü§ñ **Large Language Models** | 10 | Transformers, BERT, GPT, training at scale |
| **[3](learning/phase-03-attention.md)** | ‚ö° **Attention Innovations** | 7 | FlashAttention, efficient attention, long context |
| **[4](learning/phase-04-retrieval.md)** | üîç **Retrieval & RAG** | 6 | RAG systems, kNN-LM, semantic search |
| **[5](learning/phase-05-reasoning.md)** | üß† **Reasoning & Agents** | 12 | RLHF, chain-of-thought, agentic systems |
| **[6](learning/phase-06-architectures.md)** | üèõÔ∏è **Alternative Architectures** | 7 | RWKV, Mamba, state-space models, theory |
| **[7](learning/phase-07-interpretability.md)** | üî¨ **Interpretability** | 11 | LIME, integrated gradients, weight-sparse circuits |
| **[8](learning/phase-08-security.md)** | üõ°Ô∏è **Security & Robustness** | 7 | Alignment, jailbreaking, adversarial ML |
| **[9](learning/phase-09-advanced.md)** | üéØ **Advanced Applications** | 7 | Multimodal, scientific AI, test-time compute |
| **[10](learning/phase-10-probabilistic.md)** | üé≤ **Probabilistic Models** | 6 | Diffusion, probabilistic programming |
| **[11](learning/phase-11-vision.md)** | üëÅÔ∏è **Vision & Multimodal** | 8 | ViT, CLIP, SAM, vision-language models |
| **[12](learning/phase-12-hardware.md)** | ‚öôÔ∏è **Hardware & Systems** | 2 | Photonic computing, VLSI implementations |
| **[13](learning/phase-13-policy.md)** | üìú **Policy & Governance** | 40+ | GDPR, EU AI Act, NIST AI RMF, OCC model risk guidance |

**Total**: 132+ core papers across 13 phases (plus 40+ policy documents & frameworks)

---

## üóÇÔ∏è Repository Structure

```
papers/
‚îú‚îÄ‚îÄ README.md                    # This file - repository overview
‚îú‚îÄ‚îÄ learning-path.md             # Main learning path navigation
‚îú‚îÄ‚îÄ by-date.md                   # Chronological paper listing
‚îî‚îÄ‚îÄ learning/                    # Phase-by-phase curriculum
    ‚îú‚îÄ‚îÄ glossary.md              # Comprehensive glossary of terms & concepts
    ‚îú‚îÄ‚îÄ phase-01-foundations.md
    ‚îú‚îÄ‚îÄ phase-02-llms.md
    ‚îú‚îÄ‚îÄ phase-03-attention.md
    ‚îú‚îÄ‚îÄ phase-04-retrieval.md
    ‚îú‚îÄ‚îÄ phase-05-reasoning.md
    ‚îú‚îÄ‚îÄ phase-06-architectures.md
    ‚îú‚îÄ‚îÄ phase-07-interpretability.md
    ‚îú‚îÄ‚îÄ phase-08-security.md
    ‚îú‚îÄ‚îÄ phase-09-advanced.md
    ‚îú‚îÄ‚îÄ phase-10-probabilistic.md
    ‚îú‚îÄ‚îÄ phase-11-vision.md
    ‚îú‚îÄ‚îÄ phase-12-hardware.md
    ‚îî‚îÄ‚îÄ phase-13-policy.md
```

---

## üìä Coverage by Topic

This collection spans the full spectrum of modern AI/ML research, organized by theme:

### üèóÔ∏è Deep Learning Foundations
- Classic architectures: [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), [AlexNet](https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf), [GoogLeNet](https://arxiv.org/abs/1409.4842), [ResNet](https://arxiv.org/abs/1512.03385), [Identity Mappings in ResNets](https://arxiv.org/abs/1603.05027)
- Training techniques: [Xavier initialization](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), [Batch Normalization](https://arxiv.org/abs/1502.03167), [RNN Regularization](https://arxiv.org/abs/1409.2329)
- **Word Embeddings**: [Word2Vec](https://arxiv.org/abs/1301.3781), [GloVe](https://aclanthology.org/D14-1162/), [Seq2Seq](https://arxiv.org/abs/1409.3215) encoder-decoder architectures, [Pointer Networks](https://arxiv.org/abs/1506.03134)
- Sequence models: [LSTM](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory) üîí, time-series foundations ([MOMENT](https://arxiv.org/pdf/2402.03885))
- Generative models: [GANs](https://arxiv.org/abs/1406.2661), [Variational Lossy Autoencoder](https://arxiv.org/abs/1611.02731), diffusion models
- **Convolutional innovations**: [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122)
- **Tokenization**: [BPE](https://arxiv.org/abs/1508.07909), [SentencePiece](https://arxiv.org/abs/1808.06226), [tokenization bias](https://arxiv.org/abs/2406.16829) and [best practices](https://arxiv.org/abs/2403.01289)

### ü§ñ Large Language Models & Transformers
- **Foundational**: [Neural Machine Translation with Attention](https://arxiv.org/abs/1409.0473) (attention mechanism precursor), [Attention Is All You Need](https://arxiv.org/abs/1706.03762), [BERT](https://arxiv.org/abs/1810.04805), [GPT-3](https://arxiv.org/abs/2005.14165)
- **Scaling**: [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361) - empirical relationships between size, data, and performance
- **Modern LLMs**: [Llama 3](https://arxiv.org/abs/2407.21783), [OpenELM](https://arxiv.org/pdf/2404.14619), [EuroLLM](https://arxiv.org/pdf/2409.11741)
- **Training at Scale**: [GPipe](https://arxiv.org/abs/1811.06965) (pipeline parallelism), [Megatron-LM](https://arxiv.org/abs/1909.08053), [ZeRO](https://arxiv.org/abs/1910.02054), [model parallelism](https://arxiv.org/abs/2104.04473), [second-order optimization](https://arxiv.org/pdf/2510.09378)
- **Efficiency**: [MatMul-free models](https://arxiv.org/pdf/2406.02528), [1-bit LLMs](https://arxiv.org/pdf/2402.17764), [vocabulary optimization](https://arxiv.org/abs/2411.09009)

### ‚ö° Efficient Attention & Long Context
- FlashAttention: [IO-aware attention algorithms](https://arxiv.org/abs/2205.14135)
- Alternative mechanisms: [RetNet](https://arxiv.org/abs/2307.08621), [attention sinks](https://arxiv.org/pdf/2309.17453.pdf), [Infini-attention](https://arxiv.org/pdf/2404.07143v1.pdf)
- Hardware-aligned: [Native sparse attention](https://arxiv.org/abs/2502.11089)
- Context compression: [DeepSeek-OCR](https://arxiv.org/pdf/2510.18234), [hierarchical speculative decoding](https://arxiv.org/pdf/2404.11912v1.pdf)

### üîç Retrieval & Knowledge Systems
- RAG fundamentals: [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906), [REALM](https://arxiv.org/abs/2002.08909), [kNN-LM](https://arxiv.org/abs/1911.00172), [REFRAG](https://arxiv.org/pdf/2509.01092)
- **Long context analysis**: [Lost in the Middle](https://arxiv.org/abs/2307.03172) - reveals U-shaped performance curve in long contexts
- Advanced retrieval: [Semantic IDs](https://arxiv.org/abs/2508.10478), [table retrieval](https://arxiv.org/pdf/2404.09889), multi-table systems
- Federated approaches: [Classifier-as-retriever with adapters](https://arxiv.org/pdf/2509.16508)

### üß† Reasoning, Alignment & Agents
- **Alignment**: [RLHF](https://arxiv.org/abs/1706.03741), [PPO](https://arxiv.org/abs/1707.06347), [InstructGPT](https://arxiv.org/abs/2203.02155), [Constitutional AI](https://arxiv.org/abs/2212.08073)
- **Reasoning**: [A Simple Neural Network Module for Relational Reasoning](https://arxiv.org/abs/1706.01427), [hierarchical reasoning](https://arxiv.org/pdf/2506.21734), [recursive reasoning](https://arxiv.org/pdf/2510.04871), [reinforcement pre-training](https://arxiv.org/abs/2506.08007)
- **Agents**: [ReAct](https://arxiv.org/abs/2210.03629), [Reflexion](https://arxiv.org/abs/2303.11366), [Gato](https://arxiv.org/pdf/2205.06175), [DynaSaur](https://arxiv.org/abs/2411.01747)
- **Multi-agent**: [MAS-ZERO](https://arxiv.org/pdf/2505.14996) (zero-supervision design)
- **Efficiency**: [Small language models for agents](https://arxiv.org/abs/2506.02153)

### üèõÔ∏è Novel Architectures & Theory
- **Memory-augmented architectures**: [Neural Turing Machines](https://arxiv.org/abs/1410.5401), [Relational Recurrent Neural Networks](https://arxiv.org/abs/1806.01822)
- Alternatives to transformers: [RWKV](https://arxiv.org/abs/2305.13048), [Mamba](https://arxiv.org/pdf/2409.15254), state-space models
- **Set-based models**: [Order Matters: Sequence to Sequence for Sets](https://arxiv.org/abs/1511.06391)
- Novel approaches: [Kolmogorov-Arnold Networks (KAN)](https://arxiv.org/pdf/2404.19756), [U-Nets as belief propagation](https://arxiv.org/pdf/2404.18444)
- Theoretical foundations: [Neural Tangent Kernel](https://arxiv.org/abs/1806.07572), [manifold hypothesis](https://arxiv.org/abs/2504.01002)
- Training acceleration: [Neuron interaction networks](https://arxiv.org/pdf/2409.04434)

### üî¨ Interpretability & Analysis
- Attribution methods: [LIME](https://arxiv.org/abs/1602.04938), [Integrated Gradients](https://arxiv.org/abs/1703.01365), [SmoothGrad](https://arxiv.org/abs/1706.03825)
- Frameworks: [Rigorous interpretability science](https://arxiv.org/abs/1702.08608), [interpretation surveys](https://arxiv.org/abs/1706.07979)
- **Mechanistic interpretability**: [Weight-sparse transformers](https://cdn.openai.com/pdf/41df8f28-d4ef-43e9-aed2-823f9393e470/circuit-sparsity-paper.pdf) - training interpretable models from scratch with circuit discovery
- Evaluation: [TruthfulQA](https://arxiv.org/abs/2109.07958), [MLE-bench](https://arxiv.org/abs/2410.07095), [model calibration](https://arxiv.org/abs/1706.04599)
- Critical analysis: ["The Illusion of Thinking"](https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf), [LLM evaluation challenges](https://arxiv.org/pdf/2502.07445)

### üõ°Ô∏è Security, Safety & Robustness
- **Alignment & Safety**: [InstructGPT](https://arxiv.org/abs/2203.02155), [Constitutional AI](https://arxiv.org/abs/2212.08073)
- **Security**: [Prompt sanitization](https://arxiv.org/abs/2504.05147), [MCP security](https://arxiv.org/pdf/2504.08623), [agentic AI self-defense](https://arxiv.org/pdf/2510.13825)
- **Threats**: [Cyber threat intelligence](https://arxiv.org/abs/2503.23175), reliability concerns

### üëÅÔ∏è Computer Vision & Multimodal AI
- Vision transformers: [ViT](https://arxiv.org/abs/2010.11929), [CLIP](https://arxiv.org/abs/2103.00020), [SAM](https://arxiv.org/abs/2304.02643)
- **Speech recognition**: [Deep Speech 2](https://arxiv.org/abs/1512.02595) - end-to-end speech recognition
- Interpretability: [DeconvNet](https://arxiv.org/abs/1311.2901), [saliency maps](https://arxiv.org/abs/1312.6034), visualization techniques
- Segmentation: [All-CNN](https://arxiv.org/abs/1412.6806), [adversarial segmentation](https://arxiv.org/abs/1611.08408)
- Multimodal understanding: Vision-language models

### üéØ Advanced Applications
- **Scientific AI**: [AI scientist](https://arxiv.org/pdf/2408.06292), [scientific software generation](https://arxiv.org/pdf/2509.06503), [architecture discovery](https://arxiv.org/pdf/2507.18074)
- **Specialized**: [Audio generation](https://arxiv.org/pdf/2407.14358) (Stable Audio), [molecular dynamics](https://arxiv.org/pdf/2405.07898)
- **Tabular**: [TabPFN](https://arxiv.org/pdf/2207.01848v3.pdf) for small classification problems
- **Test-time compute**: [o3 system](https://arxiv.org/pdf/2411.04996), [consciousness in AI](https://arxiv.org/pdf/2308.08708v3.pdf)

### üé≤ Probabilistic & Generative Models
- Probabilistic programming: [Data analysis](https://papers.nips.cc/paper/6060-a-probabilistic-programming-approach-to-probabilistic-data-analysis.pdf), [scene perception](https://openaccess.thecvf.com/content_cvpr_2015/papers/Kulkarni_Picture_A_Probabilistic_2015_CVPR_paper.pdf) (Picture)
- MCMC methods: [Hamiltonian dynamics](https://arxiv.org/abs/1206.1901)
- Bayesian approaches: [Intuitive dynamics modeling](https://cocosci.berkeley.edu/tom/papers/collisions.pdf) üîí

### ‚öôÔ∏è Hardware & Systems
- Photonic computing for AI üîí
- VLSI implementations: [Log-domain diffusion networks](https://papers.nips.cc/paper_files/paper/2010/file/7bcdf75ad237b8e02e301f4091fb6bc8-Paper.pdf)
- Hardware-algorithm co-design

### üìú Policy & Governance
- **Financial services**: [OCC 2011-12](https://www.occ.gov/news-issuances/bulletins/2011/bulletin-2011-12a.pdf) (Model Risk Management), [SR 11-7](https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm) (Federal Reserve), [Model Risk Handbook](https://www.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/index-model-risk-management.html)
- **Data protection**: [GDPR](https://gdpr-info.eu/) (EU), [CCPA/CPRA](https://oag.ca.gov/privacy/ccpa) (California), [Convention 108+](https://www.coe.int/en/web/data-protection/convention108-and-protocol)
- **AI legislation**: [EU AI Act](https://artificialintelligenceact.eu/), [Executive Order 14110](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/), [Blueprint for AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/), [China's Generative AI regulations](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm), [New York State Frontier AI Model Law](https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A) (A6453A/S6953B)
- **Standards & frameworks**: [NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework), [ISO/IEC 42001](https://www.iso.org/standard/81230.html), [IEEE 7000 series](https://standards.ieee.org/featured/artificial-intelligence-systems/), [OECD AI Principles](https://oecd.ai/en/ai-principles)
- **Sector-specific**: [FDA AI/ML guidance](https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices), [EEOC AI discrimination guidance](https://www.eeoc.gov/laws/guidance/what-you-should-know-about-using-artificial-intelligence-when-making-employment), [NYC Local Law 144](https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page)
- **National security**: [Dual-use models report](https://www.ntia.gov/sites/default/files/publications/ntia-ai-open-model-report.pdf), [Export controls](https://www.bis.gov/index.php/emerging-tech-and-ai-controls), [NSCAI report](https://www.nscai.gov/2021-final-report/)
- **Responsible AI**: [Model cards](https://arxiv.org/abs/1810.03993), [Datasheets for datasets](https://arxiv.org/abs/1803.09010), [Microsoft Responsible AI Standard](https://www.microsoft.com/en-us/ai/responsible-ai), [AI Incident Database](https://incidentdatabase.ai/)

---

## ü§ù Contributing

Have a paper that should be included? Found a broken link? Want to improve explanations?

**To suggest a paper:**
1. Check if it's already in [by-date.md](by-date.md)
2. Consider: Is it influential? Does it fit the learning path?
3. Open an issue with: Title, arXiv/URL, why it's important, suggested phase

**To fix issues:**
1. Broken links: Open an issue or PR with updated URL
2. Typos/improvements: PRs welcome!
3. Better explanations: Suggest edits to "Why" annotations

---

## üìö Additional Resources

### Related Collections
- [Papers We Love](https://github.com/papers-we-love/papers-we-love) - Classic CS papers
- [Awesome Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers) - DL fundamentals
- [ML Papers of The Week](https://github.com/dair-ai/ML-Papers-of-the-Week) - Weekly updates

### Tools & Platforms
- [arXiv](https://arxiv.org/) - Preprint repository
- [Papers With Code](https://paperswithcode.com/) - Papers + implementations
- [Semantic Scholar](https://www.semanticscholar.org/) - AI-powered paper search
- [Connected Papers](https://www.connectedpapers.com/) - Visual paper exploration

### Conference Deadlines
- üéì **[AI Deadlines](https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM,AP,KR,HCI)** - Track ML/AI conference submissions

---

## üìÑ License

This repository contains links to research papers. All papers remain under their original licenses and copyrights held by authors and publishers.

The curation, organization, and annotations in this repository are provided for educational purposes.

---

## üôè Acknowledgments

Papers compiled from:
- Major AI/ML conferences (NeurIPS, ICML, ICLR, CVPR, ACL, etc.)
- Leading research institutions and labs
- arXiv preprint server
- Open access initiatives

Special thanks to the researchers, authors, and institutions making their work freely available.

---

## üì¨ Contact & Feedback

Found this helpful? Have suggestions? Want to discuss a paper?

- **Issues**: [Open an issue](../../issues) for bugs, suggestions, or paper recommendations
- **Discussions**: [Start a discussion](../../discussions) for paper analysis or learning questions

---

**Happy Reading! üìñüöÄ**

*Building knowledge, one paper at a time.*